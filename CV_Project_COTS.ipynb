{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zBiZSAWg5A1",
        "outputId": "213759ec-a2d9-4858-d259-16d11e2c158f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_RvRPyJj-IG",
        "outputId": "2ed75ea8-c422-4478-9f07-4e29117c6933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_d8jdiQvsbc",
        "outputId": "189683a2-0ebc-44bf-a81e-1e4f003deccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov  3 21:55:27 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJcOptA0kC3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ad2648-17e9-4bbe-b185-71690ab2668f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Libraries\n",
        "#!pip install wandb\n",
        "!pip install -qU wandb\n",
        "!pip install -qU bbox-utility\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "import yaml\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display_html\n",
        "tqdm.pandas()\n",
        "import glob\n",
        "from joblib import Parallel, delayed\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vfuwYkFos8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a9b19c91-6295-4b90-f14d-250c82f063c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLwfEnJhpvc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8d6bb2-5ef5-456d-d254-1fc0e37598fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autp4SvSo3dx"
      },
      "outputs": [],
      "source": [
        "FOLD      = 1 # which fold to train\n",
        "DIM       = 3000\n",
        "MODEL     = 'yolov5s6'\n",
        "BATCH     = 4\n",
        "EPOCHS    = 7\n",
        "OPTMIZER  = 'Adam'\n",
        "\n",
        "PROJECT   = 'great-barrier-reef-cots' # w&b in yolov5\n",
        "NAME      = f'{MODEL}-dim{DIM}-fold{FOLD}' # w&b for yolov5\n",
        "\n",
        "FOLD      = 4 # which fold to train\n",
        "REMOVE_NOBBOX = True # remove images with no bbox\n",
        "ROOT_DIR  = '/content/gdrive/MyDrive/tensorflow-great-barrier-reef'\n",
        "IMAGE_DIR = '/content/images' # directory to save images\n",
        "LABEL_DIR = '/content/labels' # directory to save labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qALidSNXqljC"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {IMAGE_DIR}\n",
        "!mkdir -p {LABEL_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI1HX-OvqmWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "84b3170c-298e-4e05-9796-d338a46e3a36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8ad7439aa8b5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{ROOT_DIR}/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'old_image_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{ROOT_DIR}/train_images/video_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34mf'{IMAGE_DIR}/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_path'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34mf'{LABEL_DIR}/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/tensorflow-great-barrier-reef/train.csv'"
          ]
        }
      ],
      "source": [
        "# Train Data\n",
        "df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n",
        "df['old_image_path'] = f'{ROOT_DIR}/train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\n",
        "df['image_path']  = f'{IMAGE_DIR}/'+df.image_id+'.jpg'\n",
        "df['label_path']  = f'{LABEL_DIR}/'+df.image_id+'.txt'\n",
        "df['annotations'] = df['annotations'].progress_apply(eval)\n",
        "display(df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uJUd9VRrSyv"
      },
      "outputs": [],
      "source": [
        "df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\n",
        "data = (df.num_bbox>0).value_counts(normalize=True)*100\n",
        "print(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJTUGo1_sBx1"
      },
      "outputs": [],
      "source": [
        "if REMOVE_NOBBOX:\n",
        "    df = df.query(\"num_bbox>0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9ypWQCTtUER"
      },
      "outputs": [],
      "source": [
        "def make_copy(row):\n",
        "    shutil.copyfile(row.old_image_path, row.image_path)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6jZqf58tYRD"
      },
      "outputs": [],
      "source": [
        "image_paths = df.old_image_path.tolist()\n",
        "_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(row) for _, row in tqdm(df.iterrows(), total=len(df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d_8pqlgyvGh"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOHVsEkqzFyS"
      },
      "outputs": [],
      "source": [
        "shutil.copy(\"/content/gdrive/MyDrive/tensorflow-great-barrier-reef/extra/__init__.py\", \"/content/__init__.py\")\n",
        "shutil.copy(\"/content/gdrive/MyDrive/tensorflow-great-barrier-reef/extra/coco.py\", \"/content/coco.py\")\n",
        "shutil.copy(\"/content/gdrive/MyDrive/tensorflow-great-barrier-reef/extra/utils.py\", \"/content/utils.py\")\n",
        "shutil.copy(\"/content/gdrive/MyDrive/tensorflow-great-barrier-reef/extra/version.py\", \"/content/version.py\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def voc2yolo(image_height, image_width, bboxes):\n",
        "    \"\"\"\n",
        "    voc  => [x1, y1, x2, y1]\n",
        "    yolo => [xmid, ymid, w, h] (normalized)\n",
        "    \"\"\"\n",
        "\n",
        "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
        "\n",
        "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n",
        "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n",
        "\n",
        "    w = bboxes[..., 2] - bboxes[..., 0]\n",
        "    h = bboxes[..., 3] - bboxes[..., 1]\n",
        "\n",
        "    bboxes[..., 0] = bboxes[..., 0] + w/2\n",
        "    bboxes[..., 1] = bboxes[..., 1] + h/2\n",
        "    bboxes[..., 2] = w\n",
        "    bboxes[..., 3] = h\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "def yolo2voc(image_height, image_width, bboxes):\n",
        "    \"\"\"\n",
        "    yolo => [xmid, ymid, w, h] (normalized)\n",
        "    voc  => [x1, y1, x2, y1]\n",
        "\n",
        "    \"\"\"\n",
        "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
        "\n",
        "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
        "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
        "\n",
        "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
        "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "def coco2yolo(image_height, image_width, bboxes):\n",
        "    \"\"\"\n",
        "    coco => [xmin, ymin, w, h]\n",
        "    yolo => [xmid, ymid, w, h] (normalized)\n",
        "    \"\"\"\n",
        "\n",
        "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
        "\n",
        "    # normolizinig\n",
        "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n",
        "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n",
        "\n",
        "    # converstion (xmin, ymin) => (xmid, ymid)\n",
        "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "def yolo2coco(image_height, image_width, bboxes):\n",
        "    \"\"\"\n",
        "    yolo => [xmid, ymid, w, h] (normalized)\n",
        "    coco => [xmin, ymin, w, h]\n",
        "\n",
        "    \"\"\"\n",
        "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
        "\n",
        "    # denormalizing\n",
        "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n",
        "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n",
        "\n",
        "    # converstion (xmid, ymid) => (xmin, ymin)\n",
        "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "def load_image(image_path):\n",
        "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "def draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):\n",
        "\n",
        "    image = img.copy()\n",
        "    show_classes = classes if show_classes is None else show_classes\n",
        "    colors = (0, 255 ,0) if colors is None else colors\n",
        "\n",
        "    if bbox_format == 'yolo':\n",
        "\n",
        "        for idx in range(len(bboxes)):\n",
        "\n",
        "            bbox  = bboxes[idx]\n",
        "            cls   = classes[idx]\n",
        "            cls_id = class_ids[idx]\n",
        "            color = colors[cls_id] if type(colors) is list else colors\n",
        "\n",
        "            if cls in show_classes:\n",
        "\n",
        "                x1 = round(float(bbox[0])*image.shape[1])\n",
        "                y1 = round(float(bbox[1])*image.shape[0])\n",
        "                w  = round(float(bbox[2])*image.shape[1]/2) #w/2\n",
        "                h  = round(float(bbox[3])*image.shape[0]/2)\n",
        "\n",
        "                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n",
        "                plot_one_box(voc_bbox,\n",
        "                             image,\n",
        "                             color = color,\n",
        "                             label = cls if class_name else str(get_label(cls)),\n",
        "                             line_thickness = line_thickness)\n",
        "\n",
        "    elif bbox_format == 'coco':\n",
        "\n",
        "        for idx in range(len(bboxes)):\n",
        "\n",
        "            bbox  = bboxes[idx]\n",
        "            cls   = classes[idx]\n",
        "            cls_id = class_ids[idx]\n",
        "            color = colors[cls_id] if type(colors) is list else colors\n",
        "\n",
        "            if cls in show_classes:\n",
        "                x1 = int(round(bbox[0]))\n",
        "                y1 = int(round(bbox[1]))\n",
        "                w  = int(round(bbox[2]))\n",
        "                h  = int(round(bbox[3]))\n",
        "\n",
        "                voc_bbox = (x1, y1, x1+w, y1+h)\n",
        "                plot_one_box(voc_bbox,\n",
        "                             image,\n",
        "                             color = color,\n",
        "                             label = cls if class_name else str(cls_id),\n",
        "                             line_thickness = line_thickness)\n",
        "\n",
        "    elif bbox_format == 'voc_pascal':\n",
        "\n",
        "        for idx in range(len(bboxes)):\n",
        "\n",
        "            bbox  = bboxes[idx]\n",
        "            cls   = classes[idx]\n",
        "            cls_id = class_ids[idx]\n",
        "            color = colors[cls_id] if type(colors) is list else colors\n",
        "\n",
        "            if cls in show_classes:\n",
        "                x1 = int(round(bbox[0]))\n",
        "                y1 = int(round(bbox[1]))\n",
        "                x2 = int(round(bbox[2]))\n",
        "                y2 = int(round(bbox[3]))\n",
        "                voc_bbox = (x1, y1, x2, y2)\n",
        "                plot_one_box(voc_bbox,\n",
        "                             image,\n",
        "                             color = color,\n",
        "                             label = cls if class_name else str(cls_id),\n",
        "                             line_thickness = line_thickness)\n",
        "    else:\n",
        "        raise ValueError('wrong bbox format')\n",
        "\n",
        "    return image\n",
        "\n",
        "def get_bbox(annots):\n",
        "    bboxes = [list(annot.values()) for annot in annots]\n",
        "    return bboxes\n",
        "\n",
        "def get_imgsize(row):\n",
        "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
        "    return row\n",
        "\n",
        "\n",
        "# https://www.kaggle.com/diegoalejogm/great-barrier-reefs-eda-with-animations\n",
        "def create_animation(ims):\n",
        "    fig = plt.figure(figsize=(16, 12))\n",
        "    plt.axis('off')\n",
        "    im = plt.imshow(ims[0])\n",
        "\n",
        "    def animate_func(i):\n",
        "        im.set_array(ims[i])\n",
        "        return [im]\n",
        "\n",
        "    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//12)\n",
        "\n",
        "np.random.seed(32)\n",
        "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
        "          for idx in range(1)]"
      ],
      "metadata": {
        "id": "CDPlIh-Ccvfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-ww1Sx01XGf"
      },
      "outputs": [],
      "source": [
        "df['bboxes'] = df.annotations.progress_apply(get_bbox)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4Yx603r1cht"
      },
      "outputs": [],
      "source": [
        "df['width']  = 1280\n",
        "df['height'] = 720\n",
        "display(df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeS-UG7H1lUa"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "all_bboxes = []\n",
        "bboxes_info = []\n",
        "for row_idx in tqdm(range(df.shape[0])):\n",
        "    row = df.iloc[row_idx]\n",
        "    image_height = row.height\n",
        "    image_width  = row.width\n",
        "    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n",
        "    num_bbox     = len(bboxes_coco)\n",
        "    names        = ['cots']*num_bbox\n",
        "    labels       = np.array([0]*num_bbox)[..., None].astype(str)\n",
        "    ## Create Annotation(YOLO)\n",
        "    with open(row.label_path, 'w') as f:\n",
        "        if num_bbox<1:\n",
        "            annot = ''\n",
        "            f.write(annot)\n",
        "            cnt+=1\n",
        "            continue\n",
        "        bboxes_voc  = coco2voc(bboxes_coco, image_height, image_width)\n",
        "        bboxes_voc  = clip_bbox(bboxes_voc, image_height, image_width)\n",
        "        bboxes_yolo = voc2yolo(bboxes_voc, image_height, image_width).astype(str)\n",
        "        all_bboxes.extend(bboxes_yolo.astype(float))\n",
        "        bboxes_info.extend([[row.image_id, row.video_id, row.sequence]]*len(bboxes_yolo))\n",
        "        annots = np.concatenate([labels, bboxes_yolo], axis=1)\n",
        "        string = annot2str(annots)\n",
        "        f.write(string)\n",
        "print('Missing:',cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdqw1L_f1sxR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "kf = GroupKFold(n_splits = 3)\n",
        "df = df.reset_index(drop=True)\n",
        "df['fold'] = -1\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df, groups=df.video_id.tolist())):\n",
        "    df.loc[val_idx, 'fold'] = fold\n",
        "display(df.fold.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvtN_neb11Hu"
      },
      "outputs": [],
      "source": [
        "bbox_df = pd.DataFrame(np.concatenate([bboxes_info, all_bboxes], axis=1),\n",
        "             columns=['image_id','video_id','sequence',\n",
        "                     'xmid','ymid','w','h'])\n",
        "bbox_df[['xmid','ymid','w','h']] = bbox_df[['xmid','ymid','w','h']].astype(float)\n",
        "bbox_df['area'] = bbox_df.w * bbox_df.h * 1280 * 720\n",
        "bbox_df = bbox_df.merge(df[['image_id','fold']], on='image_id', how='left')\n",
        "bbox_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJnO0VrI17t4"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "all_bboxes = np.array(all_bboxes)\n",
        "\n",
        "x_val = all_bboxes[...,0]\n",
        "y_val = all_bboxes[...,1]\n",
        "\n",
        "# Calculate the point density\n",
        "xy = np.vstack([x_val,y_val])\n",
        "z = gaussian_kde(xy)(xy)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "# ax.axis('off')\n",
        "ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n",
        "# ax.set_xlabel('x_mid')\n",
        "# ax.set_ylabel('y_mid')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dip5VeL62DGQ"
      },
      "outputs": [],
      "source": [
        "x_val = all_bboxes[...,2]\n",
        "y_val = all_bboxes[...,3]\n",
        "\n",
        "# Calculate the point density\n",
        "xy = np.vstack([x_val,y_val])\n",
        "z = gaussian_kde(xy)(xy)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 10))\n",
        "# ax.axis('off')\n",
        "ax.scatter(x_val, y_val, c=z, s=100, cmap='viridis')\n",
        "# ax.set_xlabel('bbox_width')\n",
        "# ax.set_ylabel('bbox_height')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHgVVDn72GVG"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "f, ax = plt.subplots(figsize=(12, 6))\n",
        "sns.despine(f)\n",
        "\n",
        "sns.histplot(\n",
        "    bbox_df,\n",
        "    x=\"area\", hue=\"fold\",\n",
        "    multiple=\"stack\",\n",
        "    palette=\"viridis\",\n",
        "    edgecolor=\".3\",\n",
        "    linewidth=.5,\n",
        "    log_scale=True,\n",
        ")\n",
        "ax.xaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\n",
        "ax.set_xticks([500, 1000, 2000, 5000, 10000]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcVqzdS62L7q"
      },
      "outputs": [],
      "source": [
        "df2 = df[(df.num_bbox>0)].sample(100) # takes samples with bbox\n",
        "y = 3; x = 2\n",
        "plt.figure(figsize=(12.8*x, 7.2*y))\n",
        "for idx in range(x*y):\n",
        "    row = df2.iloc[idx]\n",
        "    img           = load_image(row.image_path)\n",
        "    image_height  = row.height\n",
        "    image_width   = row.width\n",
        "    with open(row.label_path) as f:\n",
        "        annot = str2annot(f.read())\n",
        "    bboxes_yolo = annot[...,1:]\n",
        "    labels      = annot[..., 0].astype(int).tolist()\n",
        "    names         = ['cots']*len(bboxes_yolo)\n",
        "    plt.subplot(y, x, idx+1)\n",
        "    plt.imshow(draw_bboxes(img = img,\n",
        "                           bboxes = bboxes_yolo,\n",
        "                           classes = names,\n",
        "                           class_ids = labels,\n",
        "                           class_name = True,\n",
        "                           colors = colors,\n",
        "                           bbox_format = 'yolo',\n",
        "                           line_thickness = 2))\n",
        "    plt.axis('OFF')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "kf = GroupKFold(n_splits = 5)\n",
        "df = df.reset_index(drop=True)\n",
        "df['fold'] = -1\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(df, y = df.video_id.tolist(), groups=df.sequence)):\n",
        "    df.loc[val_idx, 'fold'] = fold\n",
        "display(df.fold.value_counts())"
      ],
      "metadata": {
        "id": "c9VudQ6-O_jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = []\n",
        "val_files   = []\n",
        "train_df = df.query(\"fold!=@FOLD\")\n",
        "valid_df = df.query(\"fold==@FOLD\")\n",
        "train_files += list(train_df.image_path.unique())\n",
        "val_files += list(valid_df.image_path.unique())\n",
        "len(train_files), len(val_files)"
      ],
      "metadata": {
        "id": "vC__sv7WPBfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B15bWv-2hLm"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "cwd = '/content'\n",
        "\n",
        "with open(os.path.join( cwd , 'train.txt'), 'w') as f:\n",
        "    for path in train_df.image_path.tolist():\n",
        "        f.write(path+'\\n')\n",
        "\n",
        "with open(os.path.join(cwd , 'val.txt'), 'w') as f:\n",
        "    for path in valid_df.image_path.tolist():\n",
        "        f.write(path+'\\n')\n",
        "\n",
        "data = dict(\n",
        "    path  = '/content',\n",
        "    train =  os.path.join( cwd , 'train.txt') ,\n",
        "    val   =  os.path.join( cwd , 'val.txt' ),\n",
        "    nc    = 1,\n",
        "    names = ['cots'],\n",
        "    )\n",
        "\n",
        "with open(os.path.join( cwd , 'gbr.yaml'), 'w') as outfile:\n",
        "    yaml.dump(data, outfile, default_flow_style=False)\n",
        "\n",
        "f = open(os.path.join( cwd , 'gbr.yaml'), 'r')\n",
        "print('\\nyaml:')\n",
        "print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-2BfIPO3R68"
      },
      "outputs": [],
      "source": [
        "cwd = '/content/custom.yaml'\n",
        "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "momentum: 0.937  # SGD momentum/Adam beta1\n",
        "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
        "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
        "warmup_momentum: 0.8  # warmup initial momentum\n",
        "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
        "box: 0.05 # box loss gain\n",
        "cls: 0.5  # cls loss gain\n",
        "cls_pw: 1.0  # cls BCELoss positive_weight\n",
        "obj: 1.0  # obj loss gain (scale with pixels)\n",
        "obj_pw: 1.0  # obj BCELoss positive_weight\n",
        "iou_t: 0.2  # IoU training threshold\n",
        "anchor_t: 4.0  # anchor-multiple threshold\n",
        "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
        "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
        "hsv_v: 0.3  # image HSV-Value augmentation (fraction)\n",
        "degrees: 0.0  # image rotation (+/- deg)\n",
        "translate: 0.1  # image translation (+/- fraction)\n",
        "scale: 0.5  # image scale (+/- gain)\n",
        "shear: 0.0  # image shear (+/- deg)\n",
        "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
        "flipud: 0.5  # image flip up-down (probability)\n",
        "fliplr: 0.5  # image flip left-right (probability)\n",
        "mosaic: 0.5  # image mosaic (probability)\n",
        "mixup: 0.5 # image mixup (probability)\n",
        "copy_paste: 0.0  # segment copy-paste (probability)\n",
        "\n",
        "with open(os.path.join( cwd ), 'w') as outfile:\n",
        "    yaml.dump(data, outfile, default_flow_style=False)\n",
        "\n",
        "f = open(os.path.join( cwd ), 'r')\n",
        "print('\\nyaml:')\n",
        "print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHseyDci3XSH"
      },
      "outputs": [],
      "source": [
        "# ---> YOLOv5 install <---\n",
        "%cd /content/\n",
        "!cp -r /content/gdrive/MyDrive/tensorflow-great-barrier-reef/yolov5-lib-ds /content/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "f = open('requirements.txt', 'r')\n",
        "content = f.read()\n",
        "print(content)\n",
        "f.close()\n",
        "\n",
        "print(\"Current Working Directory \\n\" , os. getcwd())\n",
        "\n",
        "from yolov5 import utils\n",
        "display = utils.notebook_init()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVotrZ3VTt7V"
      },
      "outputs": [],
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpMzOihv4uhV"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolov5/\n",
        "!python train.py --img 1280 \\\n",
        "--hyp /content/custom.yaml \\\n",
        "--batch 8 \\\n",
        "--epochs 18 \\\n",
        "--data /content/bgr.yaml \\\n",
        "--weights yolov5m.pt --workers 0\n",
        "--project {PROJECT} --name {NAME} \\\n",
        "--exist-ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPiztJEX5Lid"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = '{}/{}'.format(PROJECT, NAME)\n",
        "!ls {OUTPUT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls runs/train/exp"
      ],
      "metadata": {
        "id": "LLq1DNqbOYXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread('runs/train/exp/labels_correlogram.jpg'));"
      ],
      "metadata": {
        "id": "IL36kURPOZGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(plt.imread('runs/train/exp/train_batch0.jpg'))\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(plt.imread('runs/train/exp/train_batch1.jpg'))\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(plt.imread('runs/train/exp/train_batch2.jpg'))"
      ],
      "metadata": {
        "id": "zNFWa5n2ObBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(3, 2, figsize = (2*9,3*5), constrained_layout = True)\n",
        "for row in range(3):\n",
        "    ax[row][0].imshow(plt.imread(f'runs/train/exp/val_batch{row}_labels.jpg'))\n",
        "    ax[row][0].set_xticks([])\n",
        "    ax[row][0].set_yticks([])\n",
        "    ax[row][0].set_title(f'runs/train/exp/val_batch{row}_labels.jpg', fontsize = 12)\n",
        "\n",
        "    ax[row][1].imshow(plt.imread(f'runs/train/exp/val_batch{row}_pred.jpg'))\n",
        "    ax[row][1].set_xticks([])\n",
        "    ax[row][1].set_yticks([])\n",
        "    ax[row][1].set_title(f'runs/train/exp/val_batch{row}_pred.jpg', fontsize = 12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GfClFMebOdYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,15))\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread('runs/train/exp/results.png'));"
      ],
      "metadata": {
        "id": "JTU074YMOf_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "plt.axis('off')\n",
        "plt.imshow(plt.imread('runs/train/exp/confusion_matrix.png'));"
      ],
      "metadata": {
        "id": "5zh2jcqwOiGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in ['F1', 'PR', 'P', 'R']:\n",
        "    print(f'Metric: {metric}')\n",
        "    plt.figure(figsize=(12,10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(plt.imread(f'runs/train/exp/{metric}_curve.png'));\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Uziz7PjTOkPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img, size=768, augment=False):\n",
        "    height, width = img.shape[:2]\n",
        "    results = model(img, size=size, augment=augment)  # custom inference size\n",
        "    preds   = results.pandas().xyxy[0]\n",
        "    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n",
        "    if len(bboxes):\n",
        "        bboxes  = voc2coco(bboxes,height,width).astype(int)\n",
        "        confs   = preds.confidence.values\n",
        "        return bboxes, confs\n",
        "    else:\n",
        "        return [],[]\n",
        "\n",
        "def format_prediction(bboxes, confs):\n",
        "    annot = ''\n",
        "    if len(bboxes)>0:\n",
        "        for idx in range(len(bboxes)):\n",
        "            xmin, ymin, w, h = bboxes[idx]\n",
        "            conf             = confs[idx]\n",
        "            annot += f'{conf} {xmin} {ymin} {w} {h}'\n",
        "            annot +=' '\n",
        "        annot = annot.strip(' ')\n",
        "    return annot\n",
        "\n",
        "def show_img(img, bboxes, bbox_format='yolo'):\n",
        "    names  = ['starfish']*len(bboxes)\n",
        "    labels = [0]*len(bboxes)\n",
        "    img    = draw_bboxes(img = img,\n",
        "                           bboxes = bboxes,\n",
        "                           classes = names,\n",
        "                           class_ids = labels,\n",
        "                           class_name = True,\n",
        "                           colors = colors,\n",
        "                           bbox_format = bbox_format,\n",
        "                           line_thickness = 2)\n",
        "    return Image.fromarray(img).resize((800, 400))"
      ],
      "metadata": {
        "id": "UpdcqFsFP22b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR  = '/content/gdrive/MyDrive/tensorflow-great-barrier-reef'\n",
        "CKPT_PATH = '/content/gdrive/MyDrive/tensorflow-great-barrier-reef/reef_baseline_fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt'\n",
        "IMG_SIZE  = 9000\n",
        "CONF      = 0.25\n",
        "IOU       = 0.50\n",
        "AUGMENT   = True"
      ],
      "metadata": {
        "id": "zIyaMMkPQGEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n",
        "df['image_path'] = f'{ROOT_DIR}/train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\n",
        "df['annotations'] = df['annotations'].progress_apply(eval)\n",
        "display(df.head(2))"
      ],
      "metadata": {
        "id": "Z_6c11FDQdYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(ckpt_path, conf=0.25, iou=0.50):\n",
        "    model = torch.hub.load('/content/gdrive/MyDrive/tensorflow-great-barrier-reef/yolov5-lib-ds',\n",
        "                           'custom',\n",
        "                           path=ckpt_path,\n",
        "                           source='local',\n",
        "                           force_reload=True)  # local repo\n",
        "    model.conf = conf  # NMS confidence threshold\n",
        "    model.iou  = iou  # NMS IoU threshold\n",
        "    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n",
        "    model.multi_label = False  # NMS multiple labels per box\n",
        "    model.max_det = 1000  # maximum number of detections per image\n",
        "    return model"
      ],
      "metadata": {
        "id": "-VzhqPBtQlXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ],
      "metadata": {
        "id": "x2AY8Jy2Qp0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n",
        "image_paths = df[df.num_bbox>1].sample(100).image_path.tolist()\n",
        "for idx, path in enumerate(image_paths):\n",
        "    img = cv2.imread(path)[...,::-1]\n",
        "    bboxes, confis = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n",
        "    display(show_img(img, bboxes, bbox_format='coco'))\n",
        "    if idx>5:\n",
        "        break"
      ],
      "metadata": {
        "id": "5_DEWRrYQzUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2F9FrlGC95e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}